{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "from dotenv import load_dotenv\n",
    "from openai import OpenAI, AsyncOpenAI\n",
    "from agents import Agent, Runner, trace, function_tool, OpenAIChatCompletionsModel, input_guardrail, GuardrailFunctionOutput, gen_trace_id\n",
    "from typing import Dict\n",
    "import os\n",
    "import asyncio\n",
    "from bs4 import BeautifulSoup\n",
    "import requests\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Openai_Api_Key exists and begins sk-p\n",
      "Google_Api_Key exists and begins AIza\n",
      "Deepseek_Api_Key exists and begins sk-3\n",
      "Anthropic_Api_Key exists and begins sk-a\n",
      "Gsearch_Api_Key exists and begins AIza\n",
      "Search_Engine_Id exists and begins b5a9\n"
     ]
    }
   ],
   "source": [
    "load_dotenv(override=True)\n",
    "\n",
    "# Explicit variable assignments\n",
    "openai_api_key     = os.getenv('OPENAI_API_KEY')\n",
    "google_api_key     = os.getenv('GOOGLE_API_KEY')\n",
    "deepseek_api_key   = os.getenv('DEEPSEEK_API_KEY')\n",
    "anthropic_api_key  = os.getenv('ANTHROPIC_API_KEY')\n",
    "gsearch_api_key    = os.getenv('GSEARCH_API_KEY')\n",
    "search_engine_id   = os.getenv('SEARCH_ENGINE_ID')\n",
    "\n",
    "# List of variable names (as strings)\n",
    "var_names = [\n",
    "    \"openai_api_key\", \"google_api_key\", \"deepseek_api_key\", \"anthropic_api_key\",\n",
    "    \"gsearch_api_key\", \"search_engine_id\",\n",
    "]\n",
    "\n",
    "\n",
    "for var in var_names:\n",
    "    value = locals()[var]\n",
    "    label = var.title()\n",
    "    if value:\n",
    "        print(f\"{label} exists and begins {value[:4]}\")\n",
    "    else:\n",
    "        print(f\"{label} not set\")\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def fetch_search_links(query: str) -> list[str]:\n",
    "    \"\"\"\n",
    "    Queries the Google Custom Search API and returns a list of formatted URLs.\n",
    "   \n",
    "    Returns:\n",
    "        list[str]: A list of formatted URLs returned by the search engine.\n",
    "    \n",
    "    Raises:\n",
    "        RuntimeError: If the request fails or JSON response is invalid.\n",
    "    \"\"\"\n",
    "    url = 'https://www.googleapis.com/customsearch/v1'\n",
    "    max_results = 5\n",
    "    params = {\n",
    "        'q': query,\n",
    "        'key': gsearch_api_key,\n",
    "        'cx': search_engine_id,\n",
    "        'num': max_results\n",
    "    }\n",
    "\n",
    "    try:\n",
    "        response = requests.get(url, params=params)\n",
    "        response.raise_for_status()\n",
    "        results = response.json()\n",
    "\n",
    "        items = results.get('items', [])\n",
    "        links = [item.get('formattedUrl') for item in items if item.get('formattedUrl')]\n",
    "\n",
    "        return links\n",
    "\n",
    "    except requests.exceptions.RequestException as e:\n",
    "        raise RuntimeError(f\"Request failed: {e}\")\n",
    "    except ValueError:\n",
    "        raise RuntimeError(\"Error parsing JSON response.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def fetch_website_contents(url: str) -> str:\n",
    "    headers = {\n",
    "        \"User-Agent\": (\n",
    "            \"Mozilla/5.0 (Windows NT 10.0; Win64; x64) \"\n",
    "            \"AppleWebKit/537.36 (KHTML, like Gecko) \"\n",
    "            \"Chrome/117.0.0.0 Safari/537.36\"\n",
    "        )\n",
    "    }\n",
    "\n",
    "    try:\n",
    "        response = requests.get(url, headers=headers, timeout=10)\n",
    "        response.raise_for_status()\n",
    "        soup = BeautifulSoup(response.content, 'html.parser')\n",
    "\n",
    "        title = soup.title.get_text(strip=True) if soup.title else \"No title found\"\n",
    "\n",
    "        if soup.body:\n",
    "            for tag in soup.body([\"script\", \"style\", \"img\", \"input\", \"noscript\"]):\n",
    "                tag.decompose()\n",
    "            text = soup.body.get_text(separator=\"\\n\", strip=True)\n",
    "            text = remove_short_lines(text)\n",
    "        else:\n",
    "            text = \"\"\n",
    "\n",
    "        return f\"Webpage Title:\\n{title}\\n\\nWebpage Contents:\\n{text}\\n\"\n",
    "\n",
    "    except requests.RequestException as e:\n",
    "        return f\"[ERROR] Failed to fetch {url}: {e}\"\n",
    "    except Exception as e:\n",
    "        return f\"[ERROR] Unexpected error: {e}\"\n",
    "    \n",
    "def remove_short_lines(text: str)-> str:\n",
    "    min_words=3\n",
    "    lines = text.splitlines()\n",
    "    filtered = [line for line in lines if len(line.split()) >= min_words]\n",
    "    return \"\\n\".join(filtered)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "@function_tool\n",
    "def deep_search_tool(query: str) -> str:\n",
    "    links = fetch_search_links(query)\n",
    "    content = \"\"\n",
    "    content = f\"{content} \\nSource URLs:\\n{\"\\n\".join(links)}\"\n",
    "    for link in links:\n",
    "        content = content + f\"\\n\\n## New Search Source:\\nSource Content:\\n\" + fetch_website_contents(link)\n",
    "    \n",
    "    return content\n",
    "             \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "GEMINI_BASE_URL = \"https://generativelanguage.googleapis.com/v1beta/openai/\"\n",
    "DEEPSEEK_BASE_URL = \"https://api.deepseek.com/v1\"\n",
    "CLAUDE_BASE_URL = \"https://api.anthropic.com/v1/\"\n",
    "\n",
    "claude_client = AsyncOpenAI(base_url=CLAUDE_BASE_URL, api_key=anthropic_api_key)\n",
    "deepseek_client = AsyncOpenAI(base_url=DEEPSEEK_BASE_URL, api_key=deepseek_api_key)\n",
    "lama_client = AsyncOpenAI(base_url='http://localhost:11434/v1', api_key='ollama')\n",
    "# gemini_client = AsyncOpenAI(base_url=GEMINI_BASE_URL, api_key=google_api_key)\n",
    "\n",
    "deepseek_model = OpenAIChatCompletionsModel(model=\"deepseek-chat\", openai_client=deepseek_client)\n",
    "claude_model=OpenAIChatCompletionsModel(model=\"claude-3-7-sonnet-20250219\", openai_client=claude_client)\n",
    "llama_model = OpenAIChatCompletionsModel(model=\"llama3.2:latest\", openai_client=lama_client)\n",
    "# Gemini model does not work with OpenAi Agents SDK\n",
    "# gemini_model = OpenAIChatCompletionsModel(model=\"gemini-2.0-flash\", openai_client=gemini_client)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "sys_text = \"\"\" You are an assistant agent who can answer questions for users. \\\n",
    "            if the user asks you any question, then do not answer directly but \\\n",
    "            use the provided deep search tools only to get more recent information \\\n",
    "            related to the question. \\nYou should use the deep_search_tool tool \\\n",
    "            to get a context text which you can use to answer questions. \\nBe professional and use \\\n",
    "            the given tool and strictly answer questions using the context given by the tool.\\n\\\n",
    "            ##\\n\\n You should provide at the end of your response all the source urls, for example: 'https://www.website.com/pages'\\\n",
    "         \"\"\"\n",
    "\n",
    "# text = \"what are the stock market summary in Germany for May 2025?\"\n",
    "text = \"what are the Agentic AI trends in 2025?\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "llama_agent = Agent(name=\"llama_agent\", instructions=sys_text, model=llama_model, tools=[deep_search_tool])\n",
    "claudeAgent = Agent(name=\"claude_agent\", instructions=sys_text, model=claude_model, tools=[deep_search_tool])\n",
    "deepseek_agent = Agent(name=\"deepseek_agent: deepseek_model\", model=deepseek_model, instructions=sys_text, tools=[deep_search_tool])\n",
    "# for openai models, you need to define the model name in the model parameter, no need to define the client and model\n",
    "gpt_agent = Agent(name=\"chat_agent: gpt-4o-mini\", model=\"gpt-4o-mini\", instructions=sys_text, tools=[deep_search_tool])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "with trace(\"searcher_agent_\"):\n",
    "    result = await Runner.run(gpt_agent, text)\n",
    "    print(result.final_output)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "with trace(\"searcher_agents\"):\n",
    "    results = await asyncio.gather(\n",
    "        Runner.run(deepseek_agent, text),\n",
    "        Runner.run(claudeAgent, text),\n",
    "        Runner.run(gpt_agent, text),\n",
    "        Runner.run(llama_agent, text)\n",
    "    )\n",
    "\n",
    "outputs = [result.final_output for result in results]\n",
    "\n",
    "for output in outputs:\n",
    "    print(output + \"\\n\\n\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
